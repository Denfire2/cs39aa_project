{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":11.022331,"end_time":"2022-12-03T20:58:14.006103","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-12-03T20:58:02.983772","version":"2.3.4"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project Part 3\n\n[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Denfire2/cs39aa_project/blob/main/project-part-3.ipynb)\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/Denfire2/cs39aa_project/blob/main/project-part-3.ipynb)","metadata":{"papermill":{"duration":0.003162,"end_time":"2022-12-03T20:58:10.635762","exception":false,"start_time":"2022-12-03T20:58:10.632600","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Project Part 3: A Deep Learning Model\nIn this third and final part of the project you will train a deep learning model on your dataset. Note that the best way to do this will likely be to fine-tune an existing deep learning model such as GPT-2, BERT, etc. This is the same as what you will do in Assign 5, except that rather than using the Airline Tweet dataset you will be using your own dataset. Note that it is also possible to train a deep learning model from scratch with either PyTorch or TensorFlow/Keras, but that in the real world it will be more likely that you will want to leverage the cutting edge performance of a pre-trained deep learning model such as those available through huggingface. \n\nAs with Parts 1 and 2, this should be done in a Jupyter notebook and you should add the notebook to the repository where Assign 1 and 2 are. When you are done, you will then get the URL of your project_part3.ipynb notebook in your GitHub repository, and submit that URL here in Canvas.","metadata":{"papermill":{"duration":0.001737,"end_time":"2022-12-03T20:58:10.639808","exception":false,"start_time":"2022-12-03T20:58:10.638071","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Import statements\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nltk \nfrom collections import Counter\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.feature_extraction.text import  TfidfVectorizer\nfrom sklearn.model_selection import train_test_split \nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow import keras\nfrom math import exp","metadata":{"papermill":{"duration":0.001697,"end_time":"2022-12-03T20:58:10.643458","exception":false,"start_time":"2022-12-03T20:58:10.641761","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-04T00:40:14.449474Z","iopub.execute_input":"2022-12-04T00:40:14.450575Z","iopub.status.idle":"2022-12-04T00:40:14.458232Z","shell.execute_reply.started":"2022-12-04T00:40:14.450515Z","shell.execute_reply":"2022-12-04T00:40:14.457067Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Loading the dataset and making it compatible for tokenizing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/real-or-fake-jobs/fake_job_postings.csv', usecols=['title','description','fraudulent'])\ndf.dropna(inplace=True)\ndf\n","metadata":{"papermill":{"duration":0.001683,"end_time":"2022-12-03T20:58:10.647049","exception":false,"start_time":"2022-12-03T20:58:10.645366","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-04T00:40:17.281636Z","iopub.execute_input":"2022-12-04T00:40:17.282080Z","iopub.status.idle":"2022-12-04T00:40:17.789964Z","shell.execute_reply.started":"2022-12-04T00:40:17.282045Z","shell.execute_reply":"2022-12-04T00:40:17.788404Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                                   title  \\\n0                                       Marketing Intern   \n1              Customer Service - Cloud Video Production   \n2                Commissioning Machinery Assistant (CMA)   \n3                      Account Executive - Washington DC   \n4                                    Bill Review Manager   \n...                                                  ...   \n17875                   Account Director - Distribution    \n17876                                 Payroll Accountant   \n17877  Project Cost Control Staff Engineer - Cost Con...   \n17878                                   Graphic Designer   \n17879                         Web Application Developers   \n\n                                             description  fraudulent  \n0      Food52, a fast-growing, James Beard Award-winn...           0  \n1      Organised - Focused - Vibrant - Awesome!Do you...           0  \n2      Our client, located in Houston, is actively se...           0  \n3      THE COMPANY: ESRI – Environmental Systems Rese...           0  \n4      JOB TITLE: Itemization Review ManagerLOCATION:...           0  \n...                                                  ...         ...  \n17875  Just in case this is the first time you’ve vis...           0  \n17876  The Payroll Accountant will focus primarily on...           0  \n17877  Experienced Project Cost Control Staff Enginee...           0  \n17878  Nemsia Studios is looking for an experienced v...           0  \n17879  Who are we?Vend is an award winning web based ...           0  \n\n[17879 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>fraudulent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Marketing Intern</td>\n      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Customer Service - Cloud Video Production</td>\n      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Commissioning Machinery Assistant (CMA)</td>\n      <td>Our client, located in Houston, is actively se...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Account Executive - Washington DC</td>\n      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bill Review Manager</td>\n      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17875</th>\n      <td>Account Director - Distribution</td>\n      <td>Just in case this is the first time you’ve vis...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17876</th>\n      <td>Payroll Accountant</td>\n      <td>The Payroll Accountant will focus primarily on...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17877</th>\n      <td>Project Cost Control Staff Engineer - Cost Con...</td>\n      <td>Experienced Project Cost Control Staff Enginee...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17878</th>\n      <td>Graphic Designer</td>\n      <td>Nemsia Studios is looking for an experienced v...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17879</th>\n      <td>Web Application Developers</td>\n      <td>Who are we?Vend is an award winning web based ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17879 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.drop(df[df['description'].map(len) < 9].index, inplace=True) # delete rows of less than 10 characters in text data (as it says nothing)\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-04T00:40:20.084587Z","iopub.execute_input":"2022-12-04T00:40:20.085143Z","iopub.status.idle":"2022-12-04T00:40:20.126438Z","shell.execute_reply.started":"2022-12-04T00:40:20.085098Z","shell.execute_reply":"2022-12-04T00:40:20.125107Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(17871, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"Setup and data split for LSTM","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=10000)\ntokenizer.fit_on_texts(df.description) # Text to token conversion \n\nnum_tokens = [len(tokens) for tokens in df['description']]\nnum_tokens = np.array(num_tokens)\n\nmax_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\nmax_tokens = int(max_tokens)\nmax_tokens\nfrom keras.preprocessing.sequence import pad_sequences\n\nX = tokenizer.texts_to_sequences(df['description'])\nY = df['fraudulent'] \nX_pad = pad_sequences(X, maxlen=max_tokens)\n\nprint(X_pad.shape, Y.shape)\n\nx_train, x_test, y_train, y_test = train_test_split(X_pad, Y, test_size = 0.25, random_state = 42)\n\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)","metadata":{"papermill":{"duration":0.001702,"end_time":"2022-12-03T20:58:10.650650","exception":false,"start_time":"2022-12-03T20:58:10.648948","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-04T00:40:22.079275Z","iopub.execute_input":"2022-12-04T00:40:22.079685Z","iopub.status.idle":"2022-12-04T00:40:31.227504Z","shell.execute_reply.started":"2022-12-04T00:40:22.079653Z","shell.execute_reply":"2022-12-04T00:40:31.226453Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"(17871, 3007) (17871,)\n(13403, 3007) (13403,)\n(4468, 3007) (4468,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Actual LSTM model tuning. This was annoying as the lower the batch size the larger the steps. I dont have the strongest computer so fiting the model took awhile (2+hours per run) before I finally managed to find a balance between accuracy and being able to see the changes quickly. Epochs were tested at 50 and 20 before finaly settling on 5 as both initial tests did not trigger the early stopping. batch size was also an annoyance that went into the long fitting times: size was tested at 42, 64, and 128 before I chose 256. This was to speed up run time (still slow af)","metadata":{}},{"cell_type":"code","source":"model_ker = keras.Sequential()\nmodel_ker.add(keras.layers.Embedding(20000, 100, input_length=max_tokens))\nmodel_ker.add(keras.layers.LSTM(100, dropout=0.5, recurrent_dropout=0.5))\nmodel_ker.add(keras.layers.Dense(1, activation='sigmoid'))\n\nmodel_ker.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nepochs = 5\nbatch_size = 256\n\ncallback = (keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.001))\n\nhistory = model_ker.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1 ,callbacks=[callback])\naccr = model_ker.evaluate(x_test, y_test)","metadata":{"papermill":{"duration":0.001749,"end_time":"2022-12-03T20:58:10.654334","exception":false,"start_time":"2022-12-03T20:58:10.652585","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-04T01:28:29.962760Z","iopub.execute_input":"2022-12-04T01:28:29.963210Z","iopub.status.idle":"2022-12-04T03:17:45.357733Z","shell.execute_reply.started":"2022-12-04T01:28:29.963172Z","shell.execute_reply":"2022-12-04T03:17:45.356647Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/5\n48/48 [==============================] - 1261s 26s/step - loss: 0.2824 - accuracy: 0.9425 - val_loss: 0.1802 - val_accuracy: 0.9553\nEpoch 2/5\n48/48 [==============================] - 1247s 26s/step - loss: 0.1760 - accuracy: 0.9522 - val_loss: 0.1529 - val_accuracy: 0.9597\nEpoch 3/5\n48/48 [==============================] - 1252s 26s/step - loss: 0.1129 - accuracy: 0.9653 - val_loss: 0.1324 - val_accuracy: 0.9657\nEpoch 4/5\n48/48 [==============================] - 1242s 26s/step - loss: 0.0638 - accuracy: 0.9789 - val_loss: 0.1384 - val_accuracy: 0.9694\nEpoch 5/5\n48/48 [==============================] - 1239s 26s/step - loss: 0.0414 - accuracy: 0.9863 - val_loss: 0.1472 - val_accuracy: 0.9739\n140/140 [==============================] - 315s 2s/step - loss: 0.1573 - accuracy: 0.9693\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The actual Predictions of real vs fake jobs condenced into a readable number","metadata":{}},{"cell_type":"code","source":"pred_lstm = model_ker.predict(x_test,verbose=1,use_multiprocessing=True)\npred = pred_lstm > 1.0e-1\npred_lstm_rounded = pred.astype(int)\nprint('LSTM Model test dataset accuracy: {0:0.4f}'.format(metrics.accuracy_score(y_test, pred_lstm_rounded)))","metadata":{"execution":{"iopub.status.busy":"2022-12-04T03:39:59.137639Z","iopub.execute_input":"2022-12-04T03:39:59.138108Z","iopub.status.idle":"2022-12-04T03:45:08.451747Z","shell.execute_reply.started":"2022-12-04T03:39:59.138073Z","shell.execute_reply":"2022-12-04T03:45:08.450796Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"140/140 [==============================] - 309s 2s/step\nLSTM Model test dataset accuracy: 0.9573\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Final analysis: LSTM had the about the same accuracy as the baseline model used in part 2. and while you might be able to get a higher accuracy, the time it takes to run through will not be viable in the long run/ business sense. ","metadata":{}}]}